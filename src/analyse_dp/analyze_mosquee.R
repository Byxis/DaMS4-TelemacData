library(keras3)
library(tensorflow)

# -- Configuration Chemins --
DATA_DIR <- "../data" 
if(!dir.exists(DATA_DIR)) DATA_DIR <- "./data"

MODEL_PATH <- "models/deeplearning/telemac_deep_model.keras"
STATS_PATH <- "normalization_stats.RData"
POINTS_PATH <- "../RData/points_interet.RData"
if(!file.exists(POINTS_PATH)) POINTS_PATH <- "RData/points_interet.RData"

# Load Model & Stats
if (!file.exists(MODEL_PATH) || !file.exists(STATS_PATH)) {
  stop("Model or stats file missing.")
}

load(STATS_PATH)
model <- load_model(MODEL_PATH)

files <- list.files(DATA_DIR, pattern = "_maxH_sully.csv", full.names = TRUE)
if (length(files) == 0) stop("No data files found.")

# -- Load Points of Interest --
if (!file.exists(POINTS_PATH)) {
  stop(paste("Fichier des points d'intérêt introuvable:", POINTS_PATH))
}
load(POINTS_PATH) # loads 'points_interet'

# Search for "mosquee" (fuzzy match)
locales <- points_interet$coordoneesLocales
matches <- grep("mosqu", names(locales), ignore.case = TRUE)

if (length(matches) == 0) {
  stop("Aucun point trouvé contenant 'mosque' dans points_interet. Noms disponibles : ", paste(names(locales), collapse=", "))
}

target_name <- names(locales)[matches[1]]
coords <- locales[[target_name]]
cat("Point trouvé :", target_name, "\n")
print(coords)

# Access logic (handling list or vector structure)
target_row <- coords["row"]
target_col <- coords["col"]

# If names are row.y / col.x (generated by some merge operations in previous history), handle it
if(is.na(target_row)) target_row <- coords["row.y"]
if(is.na(target_col)) target_col <- coords["col.x"]

if(is.na(target_row) || is.na(target_col)) {
    # Fallback to indices 1 and 2 if names are missing
    target_row <- coords[1]
    target_col <- coords[2]
}

target_row <- as.numeric(target_row)
target_col <- as.numeric(target_col)

cat("Coordonnées Matrice : Ligne =", target_row, ", Colonne =", target_col, "\n")

real_values <- numeric(length(files))
pred_values <- numeric(length(files))

cat("Processing", length(files), "files for", target_name, "...\n")

for (i in seq_along(files)) {
  f <- files[i]
  base_name <- basename(f)
  
  # Parse params
  params_part <- gsub(".*=(.*)_maxH.*", "\\1", base_name)
  params <- as.numeric(unlist(strsplit(params_part, ",")))[1:8]
  
  # Read Real
  mat_real <- as.matrix(read.csv(f, header = TRUE, row.names = 1))
  
  # Predict
  x_input <- matrix((params - X_mean) / X_std, nrow = 1)
  pred_tensor <- model %>% predict(x_input, verbose = 0)
  mat_pred <- pred_tensor[1, , , 1]
  mat_pred <- t(mat_pred) # Transpose to match orientation
  
  # Extract values
  real_values[i] <- mat_real[target_row, target_col]
  pred_values[i] <- mat_pred[target_row, target_col]
  
  if (i %% 50 == 0) cat(i, "/", length(files), "\n")
}

# Calculate R2
sse <- sum((real_values - pred_values)^2)
sst <- sum((real_values - mean(real_values))^2)
r_squared <- 1 - (sse / sst)

# --- Graphique ---

plot_path <- "Performance_DeepLearning_Mosquee.png"
limit_range <- range(c(real_values, pred_values))

png(filename = plot_path, width = 800, height = 800, res = 120)

plot(real_values, pred_values, 
     xlab = "Hauteurs d'eau réelles (Telemac)", 
     ylab = "Hauteurs d'eau prédites (Deep Learning)",
     main = paste("Performance DeepLearning -", target_name),
     pch = 16, 
     col = rgb(0.2, 0.4, 0.6, 0.4), # Bleu avec transparence
     xlim = limit_range, 
     ylim = limit_range,
     asp = 1) 

abline(a = 0, b = 1, col = "red", lwd = 2, lty = 2)

text(x = limit_range[1], y = limit_range[2], 
     labels = paste("R² =", round(r_squared, 4)), 
     pos = 4, cex = 1.2, font = 2, col = "darkred")

grid()
dev.off()

cat("Graphique de performance exporté vers :", plot_path, "\n")
cat("R2 =", r_squared, "\n")
